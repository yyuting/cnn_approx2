import numpy
import tensorflow as tf
import skimage.io
import os

OUTPUT_KEY = '_output_key'
COMPILE_NAME_ATTR = '_compiler_name'

unet_default_args = {
'nlayers': 2,
'feature_base': 4,
'filter_size': 3,
'pool_size': 2,
'activation': 'none',
'double_feature': True,
'less_conv': False,
'const_bias': False,
'const_std': None,
}

training_default_args = {
'iters': 10000,
'prev_stage': None,
'loss': 'L2',
'piecewise_delta': 0.3,
'L1+L2_scale': 1.0,
'batch_size': [40, 20, 10],
'learning_rate': 0.001,
'validate_until': 10,
'weight_regularizer': 0,
'regularize_bias': True,
'regularizer_loss': 'L1'}

def is_eq(a, b, threshold=1e-2):
    """
    a, b can be scalars or arrays
    return True if the elementwise difference between a and b are smaller to a threshold
    """
    if isinstance(a, (list, numpy.ndarray)):
        return (abs(a - b) < threshold).all()
    else:
        return abs(a - b) < threshold
    
def generate_feed_dicts(test_cases, input_tensors):
    """
    Given test_cases indexed by ArgumentArray instances,
    input_tensors generated by ArgumentArray instances with the same name,
    output list of feed_dicts that can be used to evaluate the output tensor
    """
    assert len(test_cases) == 2, "Test cases must include inputs and outputs"
    test_inputs = test_cases[0]
    test_outputs = test_cases[1]
    test_lens = [len(val) for val in test_inputs.values()]
    test_len = test_lens[0]
    assert all([l == test_len for l in test_lens]), "Test inputs lengths should be the same"
    assert len(test_outputs) == test_len, "Test output should have the same length as inputs"
    
    name_tensor_lookup = {getattr(tensor, COMPILE_NAME_ATTR) : tensor for tensor in input_tensors}
    array_tensor_lookup = {}
    for key in test_inputs.keys():
        if key in name_tensor_lookup.keys():
            array_tensor_lookup[key] = name_tensor_lookup[key]
    
    assert len(array_tensor_lookup) == len(input_tensors), "Test case should include data for all inputs"
    
    feed_dicts = []
    for i in range(test_len):
        new_dict = {array_tensor_lookup[key]: value[i] for key, value in test_inputs.items() if key in array_tensor_lookup.keys()}
        #new_dict[OUTPUT_KEY] = test_outputs[i]
        feed_dicts.append([new_dict, test_outputs[i]])
    
    return feed_dicts

def check_output(test_cases, input_tensors, output_tensor, sess, check_save=False, assert_true=True):
    if test_cases is None:
        return
    feed_dicts = generate_feed_dicts(test_cases, input_tensors)
    output_vals = []
    for i, feed_dict in enumerate(feed_dicts):
        output_val = output_tensor.eval(feed_dict=feed_dict[0], session=sess)
        output_vals.append(output_val)
        if assert_true:
            assert is_eq(output_val, feed_dict[1]), (output_val, feed_dict[1])
        if check_save is True:
            skimage.io.imsave('out' + str(i) + '.png', numpy.clip(numpy.squeeze(output_val), 0.0, 1.0))
    return output_vals
    
def tensor_conv2d(X, Y, filter_size=None):
    if filter_size is None:
        try:
            filter_size_x = int(Y.shape.as_list()[0])
            filter_size_y = int(Y.shape.as_list()[1])
            filter_size = [filter_size_x, filter_size_y]
        except:
            pass
    if filter_size is None:
        return tf.nn.conv2d(X, Y, [1, 1, 1, 1], "SAME")
    else:
        pad_x_size = filter_size[0] // 2
        pad_y_size = filter_size[1] // 2
        paddings = tf.constant([[0, 0], [pad_x_size, pad_x_size], [pad_y_size, pad_y_size], [0, 0]])
        X_pad = tf.pad(X, paddings, "REFLECT")
        return tf.nn.conv2d(X_pad, Y, [1, 1, 1, 1], "VALID")
    
def get_approxnode(x, x_out, _output_array, in_channels=None, out_channels=None):
    out_shape = x.shape.as_list()
    if in_channels is None:
        in_channels = out_shape[-1]
    if out_channels is None:
        try:
            out_channels = _output_array.shape.as_list()[-1]
            assert isinstance(out_channels, int)
        except:
            out_channels = in_channels
    if out_channels != in_channels:
        out_shape[-1] = out_channels
    x_out = tf.placeholder(x.dtype, out_shape)
    approxnode = ApproxNode(x, x_out, in_channels, out_channels)
    approxnode.get_approx_ind('orig', output=_output_array)
    return approxnode
    
class ApproxNode:

    def __init__(self, in_pl, out_pl, in_channels, out_channels):
        """
        in_pl: input placeholder for training/testing input data
        out_pl: output placeholder for training/testing ground output data
        """
        self.in_pl = in_pl
        self.out_pl = out_pl
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.approx_list = []
        
    def get_approx_ind(self, name, **kw):
        if name == 'orig':
            ind = self.find_approx_exists(name, {}, {})
            if ind >= 0:
                return ind
            new_approx = {
            'name': 'orig',
            'output': kw['output']}
        elif name == 'unet':
            ind = self.find_approx_exists(name, unet_default_args, kw)
            if ind < 0:
                new_approx = self.create_unet(**kw)
            else:
                return ind
        else:
            raise ValueError("Unknown approx name")
        self.approx_list.append(new_approx)
        return len(self.approx_list) - 1
            
    def find_approx_exists(self, name, default_dict, kw):
        for i, approx in enumerate(self.approx_list):
            if approx['name'] == name:
                success = True
                for key in default_dict.keys():
                    default_val = default_dict[key]
                    if kw.get(key, default_val) != approx.get(key, default_val):
                        success = False
                        break
                if success is True:
                    return i
        return -1
            
    def get_approx(self, name, **kw):
        return self.approx_list[self.get_approx_ind(name, kw)]
        
    def clear_network(self, ind):
        """
        re-initialize all the weights.
        """
        approx = self.approx_list[ind]
        if 'sess' in approx.keys():
            sess = approx['sess']
            sess.run(tf.global_variables_initializer())
        
    def train_approx(self, ind, feed_in, feed_out, iter=1000, learning_rate=0.001, do_save=False, save_every=100, saver_dir='saver', read_from=None):
        """
        if do_save = True, save session to saver_dir in save_every iters
        if read_from is not None, read the data stored in dir read_from, and train from there.
        """
        assert len(feed_in) == len(feed_out)
        data_len = len(feed_in)
        approx = self.approx_list[ind]
        loss = approx['loss']
        temp = set(tf.all_variables())
        minimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
        train_step = minimizer.minimize(loss)
        
        if 'sess' in approx.keys():
            sess = approx['sess']
            sess.run(tf.initialize_variables(set(tf.all_variables()) - temp))
        else:
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
        
        saver = tf.train.Saver(dict(approx['weights'], **approx['biases']))
            
        if read_from is not None:
            read_path = os.path.join(os.path.abspath(os.getcwd()), read_from)
            saver.restore(sess, tf.train.latest_checkpoint(read_path))
            print("Reading from", read_path)
            
        if do_save:
            saver_dir = os.path.join(os.path.abspath(os.getcwd()), saver_dir, create_unique_name(approx))
            print("Logging training to", saver_dir)
        
        for i in range(iter):
            ind = numpy.random.randint(0, data_len)
            feed_dict = {self.in_pl: feed_in[ind], self.out_pl: feed_out[ind]}
            sess.run(train_step, feed_dict=feed_dict)
            print(loss.eval(feed_dict=feed_dict, session=sess))
            if do_save and i % save_every == 0:
                saver.save(sess, saver_dir)
                
        approx['sess'] = sess
        
        if do_save:
            saver.save(sess, saver_dir)
        
    def predict_approx(self, ind, test_in, test_out, value_name='output'):
        approx = self.approx_list[ind]
        value = approx[value_name]
        if approx['name'] != 'orig':
            assert 'sess' in approx.keys(), "Model must be trained with a valid sess first"
            sess = approx['sess']
        else:
            sess = tf.Session()
        ans_list = []
        for i in range(len(test_in)):
            input = test_in[i]
            output = test_out[i]
            ans = value.eval(feed_dict={self.in_pl: input, self.out_pl: output}, session=sess)
            ans_list.append(ans)
        return ans_list
            
    def create_unet(self, nlayers=2, feature_base=4, filter_size=3, pool_size=2, from_queue=False, in_batch=None, out_batch=None, is_const_bias=False, batch_norm=False, const_std=None, passthrough_op='concat', double_feature=True):
        """
        nlayes: number of layers in u-net
        feature_base: number of features in 1st layer of u-net
        filter_size: size of conv kernels
        pool_size: size of max pooling kernels
        
        Code modified from tf_unet
        https://github.com/jakeret/tf_unet
        """
        #TODO: what's the output shape? currently we assume output shape is the same as input shape
        
        def get_std(features):
            return numpy.sqrt(2 / (filter_size ** 2 * features))
            
        def get_weight(shape, std):
            if const_std is not None:
                std = const_std
            return tf.Variable(tf.truncated_normal(shape, stddev=std))
            
        def get_bias(shape, ignore, const=None):
            if is_const_bias or const is not None:
                const = 0.0
                return tf.Variable(tf.constant(const, shape=shape))
            else:
                return get_weight(shape, ignore)
            #return tf.Variable(tf.constant(0.0, shape=shape))
            
        def conv2d(input, filter, bias, gamma, name):
            if not batch_norm:
                return tf.nn.relu(tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding="SAME") + bias)
            else:
                linout = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding="SAME")
                conv_bn = batch_normalization(linout, bias, gamma, name)
                return tf.nn.relu(conv_bn)
        
        def record_weights(w, b, gamma, name):
            weights[name + 'w'] = w
            biases[name + 'b'] = b
            if gamma is not None and batch_norm:
                weights[name + 'gamma'] = gamma
            
        def batch_normalization(x, bias, gamma, name):
            if False:
                batch_mean, batch_var = tf.nn.moments(x, [0,1,2])
                ema = tf.train.ExponentialMovingAverage(decay=0.9)
                
                if True:
                    final_mean = ema.average(batch_mean)
                    final_var = ema.average(batch_var)
                else:
                    ema_apply_op = ema.apply([batch_mean, batch_var])
                    with tf.control_dependencies([ema_apply_op]):
                        final_mean = batch_mean
                        final_var = batch_var
                
                ema_vars[name+'mean'] = final_mean
                ema_vars[name+'var'] = final_var
                normed = tf.nn.batch_normalization(x, final_mean, final_var, bias, gamma, 1e-3)
                return normed
            else:
                return x + bias
            
        if from_queue is True:
            assert in_batch is not None and out_batch is not None
            
        down_pyramid = []
        if from_queue:
            in_node = in_batch
        else:
            in_node = self.in_pl
        weights = {}
        biases = {}
        ema_vars = {}
        
        for layer in range(nlayers):
            if double_feature:
                features = 2 ** layer * feature_base
                prev_features = features // 2
            else:
                features = feature_base
                prev_features = features
                
            std = get_std(features)
            if layer == 0:
                w1 = get_weight([filter_size, filter_size, self.in_channels, features], std)
            else:
                w1 = get_weight([filter_size, filter_size, prev_features, features], std)
            b1 = get_bias([features], std)
            w2 = get_weight([filter_size, filter_size, features, features], std)
            b2 = get_bias([features], std)
            if batch_norm:
                gamma1 = get_bias([features], std, const=1.0)
                gamma2 = get_bias([features], std, const=1.0)
            else:
                gamma1 = None
                gamma2 = None
            w1_name = 'down_conv' + str(layer) + '1'
            w2_name = 'down_conv' + str(layer) + '2'
            record_weights(w1, b1, gamma1, w1_name)
            record_weights(w2, b2, gamma2, w2_name)
            
            conv1 = conv2d(in_node, w1, b1, gamma1, w1_name)
            conv2 = conv2d(conv1, w2, b2, gamma2, w2_name)
            down_pyramid.append(conv2)
            
            if layer < nlayers - 1:
                pool_down = tf.nn.max_pool(conv2, ksize=[1, pool_size, pool_size, 1], strides=[1, pool_size, pool_size, 1], padding="SAME")
                in_node = pool_down
            else:
                in_node = conv2
            
        for layer in range(nlayers-2, -1, -1):
            if double_feature:
                features = 2 ** (layer + 1) * feature_base
                prev_features = features // 2
            else:
                features = feature_base
                prev_features = features
            std = get_std(features)
            w_deconv = get_weight([pool_size, pool_size, prev_features, features], std)
            b_deconv = get_bias([prev_features], std)
            if batch_norm:
                gamma_deconv = get_bias([prev_features], std, const=1.0)
            else:
                gamma_deconv = None
            
            in_shape = tf.shape(in_node)
            if double_feature:
                out_shape = tf.stack([in_shape[0], in_shape[1]*2, in_shape[2]*2, in_shape[3]//2])
            else:
                out_shape = tf.stack([in_shape[0], in_shape[1]*2, in_shape[2]*2, in_shape[3]])
            deconv = tf.nn.relu(tf.nn.conv2d_transpose(in_node, w_deconv, out_shape, strides=[1, pool_size, pool_size, 1], padding="SAME") + b_deconv)
            if passthrough_op == 'concat':
                passthrough = tf.concat([down_pyramid[layer], deconv], 3)
                w1 = get_weight([filter_size, filter_size, features, prev_features], std)
            elif passthrough_op == 'plus':
                passthrough = down_pyramid[layer] + deconv
                w1 = get_weight([filter_size, filter_size, prev_features, prev_features], std)
            else:
                raise
            
            b1 = get_bias([prev_features], std)
            gamma1 = get_bias([prev_features], std, const=0.0)
            w2 = get_weight([filter_size, filter_size, prev_features, prev_features], std)
            b2 = get_bias([prev_features], std)
            if batch_norm:
                gamma1 = get_bias([prev_features], std, const=1.0)
                gamma2 = get_bias([prev_features], std, const=1.0)
            else:
                gamma1 = None
                gamma2 = None
            
            wd_name = 'deconv' + str(layer)
            w1_name = 'up_conv' + str(layer) + '1'
            w2_name = 'up_conv' + str(layer) + '2'
            record_weights(w_deconv, b_deconv, gamma_deconv, wd_name)
            record_weights(w1, b1, gamma1, w1_name)
            record_weights(w2, b2, gamma2, w2_name)
            
            conv1 = conv2d(passthrough, w1, b1, gamma1, w1_name)
            conv2 = conv2d(conv1, w2, b2, gamma2, w2_name)
            in_node = conv2
            
        w_out = get_weight([1, 1, feature_base, self.out_channels], std)
        b_out = get_bias([self.out_channels], std)
        if batch_norm:
            gamma_out = get_bias([self.out_channels], std, const=1.0)
        else:
            gamma_out = None
        
        wo_name = 'output'
        record_weights(w_out, b_out, gamma_out, wo_name)
        
        conv_out = conv2d(in_node, w_out, b_out, gamma_out, wo_name)
        
        if from_queue:
            out_node = out_batch
        else:
            out_node = self.out_pl
        diff = tf.square(out_node - conv_out)
        loss = tf.reduce_mean(diff)

        approx = {
        'name': 'unet',
        'output': conv_out,
        'loss': loss,
        'weights': weights,
        'biases': biases,
        'nlayers': nlayers,
        'feature_base': feature_base,
        'filter_size': filter_size,
        'pool_size': pool_size,
        'from_queue': from_queue,
        'ema_vars': ema_vars}
        return approx
        
def create_unique_name(approx):
    """
    create a unique name for an approx dict
    """
    if approx['name'] == 'unet':
        ans = '_'.join([approx['name'], str(approx['nlayers']), str(approx['feature_base']), str(approx['filter_size']), str(approx['pool_size'])])
    else:
        raise "Cannot recognize name"
    return ans
        
def read_and_save_non_batch(path, is_color=True, multiples=1):
    files = os.listdir(path)
    imgs = []
    for file in files:
        try:
            img = skimage.io.imread(path + '/' + file)
            img = skimage.img_as_float(img)
            img = img[:img.shape[0]//multiples*multiples, :img.shape[1]//multiples*multiples]
            img = img.reshape((1,) + img.shape)
            if is_color and len(img.shape) == 4 and img.shape[3] == 3:
                imgs.append(img)
            elif not is_color:
                if len(img.shape) == 3:
                    imgs.append(img.reshape(img.shape + (1,)))
                elif len(img.shape) == 4 and img.shape[3] == 1:
                    imgs.append(img)
        except:
            pass
    return imgs